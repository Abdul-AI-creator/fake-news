{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_SEQUENCE_LENGTH = 5000\n",
    "MAX_NUM_WORDS = 25000\n",
    "EMBEDDING_DIM = 300\n",
    "TEST_SPLIT = 0.2\n",
    "\n",
    "TEXT_DATA = 'data/fake_or_real_news.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define a function that allows us to evaluate our models\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "def evaluate_model(predict_fun, X_train, y_train, X_test, y_test):\n",
    "    '''\n",
    "    evaluate the model, both training and testing errors are reported\n",
    "    '''\n",
    "    # training error\n",
    "    y_predict_train = predict_fun(X_train)\n",
    "    train_acc = accuracy_score(y_train,y_predict_train)\n",
    "    \n",
    "    # testing error\n",
    "    y_predict_test = predict_fun(X_test)\n",
    "    test_acc = accuracy_score(y_test,y_predict_test)\n",
    "    \n",
    "    return train_acc, test_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# estimate 95% confidence interval on error\n",
    "\n",
    "# NOTE: based on conversation on stackexchange: \n",
    "# https://stats.stackexchange.com/questions/247551/how-to-determine-the-confidence-of-a-neural-network-prediction\n",
    "# towards bottom of the page.\n",
    "\n",
    "from math import sqrt\n",
    "\n",
    "def error_conf(error, n):\n",
    "    term = 1.96*sqrt((error*(1-error))/n)\n",
    "    lb = error - term\n",
    "    ub = error + term\n",
    "    \n",
    "    return lb, ub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read in our data and preprocess it\n",
    "\n",
    "df = pd.read_csv(TEXT_DATA)\n",
    "df.drop(labels=['id','title'], axis='columns', inplace=True)\n",
    "# only select stories with lengths gt 0 -- there are some texts with len = 0\n",
    "mask = list(df['text'].apply(lambda x: len(x) > 0))\n",
    "df = df[mask]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 6335 texts.\n"
     ]
    }
   ],
   "source": [
    "# prepare text samples and their labels\n",
    "\n",
    "texts = df['text']\n",
    "labels = df['label']\n",
    "\n",
    "print('Found %s texts.' %texts.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plot the distribution of article lengths in terms of word counts\n",
    "\n",
    "text_lengths = texts.apply(lambda x: len(x.split(\" \")))\n",
    "plt.hist(text_lengths)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set up vector models for training and testing\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "# data vectorizer\n",
    "vectorizer = CountVectorizer(analyzer = \"word\", \n",
    "                             binary = True, \n",
    "                             min_df = 2,\n",
    "                             stop_words='english')\n",
    "docarray = vectorizer.fit_transform(texts).toarray()\n",
    "docterm = pd.DataFrame(docarray, columns=vectorizer.get_feature_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create training and test data\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "docterm_train, docterm_test, y_train, y_test = train_test_split(docterm, labels, test_size=TEST_SPLIT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Naive Bayes Model\n",
    "\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "model = MultinomialNB()\n",
    "model.fit(docterm_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Accuracy: 93.53%\n",
      "Testing Accuracy: 89.98%\n"
     ]
    }
   ],
   "source": [
    "# evaluate model\n",
    "\n",
    "train_acc, test_acc = evaluate_model(model.predict, docterm_train, y_train, docterm_test, y_test)\n",
    "print(\"Training Accuracy: {:.2f}%\".format(train_acc*100))\n",
    "print(\"Testing Accuracy: {:.2f}%\".format(test_acc*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "95% confidence interval: 88.32%-91.63%\n"
     ]
    }
   ],
   "source": [
    "# estimate 95% confidence interval\n",
    "\n",
    "n = docterm_test.shape[0]\n",
    "lb, ub = error_conf(1-test_acc, n)\n",
    "\n",
    "print(\"95% confidence interval: {:.2f}%-{:.2f}%\".format((1-ub)*100,(1-lb)*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convolutional DNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 98817 unique tokens.\n",
      "Shape of data tensor: (6335, 5000)\n",
      "Shape of label tensor: (6335,)\n"
     ]
    }
   ],
   "source": [
    "# vectorize the text samples into a 2D integer tensor \n",
    "\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.utils import to_categorical\n",
    "\n",
    "tokenizer = Tokenizer(num_words=MAX_NUM_WORDS)\n",
    "tokenizer.fit_on_texts(texts)\n",
    "sequences = tokenizer.texts_to_sequences(texts)\n",
    "\n",
    "word_index = tokenizer.word_index\n",
    "num_words = min(MAX_NUM_WORDS, len(word_index)) + 1\n",
    "data = pad_sequences(sequences, \n",
    "                     maxlen=MAX_SEQUENCE_LENGTH, \n",
    "                     padding='pre', \n",
    "                     truncating='pre')\n",
    "\n",
    "print('Found %s unique tokens.' % len(word_index))\n",
    "print('Shape of data tensor:', data.shape)\n",
    "print('Shape of label tensor:', labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split the data into a training set and a validation set   \n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "x_train, x_val, y_train, y_val = train_test_split(data, \n",
    "                                                  labels.apply(lambda x: 0 if x == 'FAKE' else 1), \n",
    "                                                  test_size=TEST_SPLIT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_1 (Embedding)      (None, 5000, 300)         7500300   \n",
      "_________________________________________________________________\n",
      "conv1d_1 (Conv1D)            (None, 4996, 128)         192128    \n",
      "_________________________________________________________________\n",
      "global_max_pooling1d_1 (Glob (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 128)               16512     \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 1)                 129       \n",
      "=================================================================\n",
      "Total params: 7,709,069\n",
      "Trainable params: 7,709,069\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# build a 1D convnet with global maxpooling                                                                      \n",
    "\n",
    "from keras import layers\n",
    "from keras.models import Sequential\n",
    "\n",
    "model = Sequential(\n",
    "    [\n",
    "        # part 1: word and sequence processing\n",
    "        layers.Embedding(num_words,\n",
    "                         EMBEDDING_DIM, \n",
    "                         input_length=MAX_SEQUENCE_LENGTH,\n",
    "                         trainable=True),\n",
    "        layers.Conv1D(128, 5, activation='relu'),\n",
    "        layers.GlobalMaxPooling1D(),\n",
    "        \n",
    "        # part 2: classification\n",
    "        layers.Dense(128, activation='relu'),\n",
    "        layers.Dense(1, activation='sigmoid')\n",
    "    ])\n",
    "\n",
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer='rmsprop',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 5068 samples, validate on 1267 samples\n",
      "Epoch 1/10\n",
      "5068/5068 [==============================] - 24s 5ms/step - loss: 0.4608 - acc: 0.7873 - val_loss: 0.2281 - val_acc: 0.9171\n",
      "Epoch 2/10\n",
      "5068/5068 [==============================] - 19s 4ms/step - loss: 0.1346 - acc: 0.9617 - val_loss: 0.1744 - val_acc: 0.9266\n",
      "Epoch 3/10\n",
      "5068/5068 [==============================] - 19s 4ms/step - loss: 0.0371 - acc: 0.9935 - val_loss: 0.0941 - val_acc: 0.9590\n",
      "Epoch 4/10\n",
      "5068/5068 [==============================] - 19s 4ms/step - loss: 0.0060 - acc: 0.9998 - val_loss: 0.0909 - val_acc: 0.9597\n",
      "Epoch 5/10\n",
      "5068/5068 [==============================] - 19s 4ms/step - loss: 0.0015 - acc: 1.0000 - val_loss: 0.0879 - val_acc: 0.9645\n",
      "Epoch 6/10\n",
      "5068/5068 [==============================] - 19s 4ms/step - loss: 1.9499e-04 - acc: 1.0000 - val_loss: 0.0857 - val_acc: 0.9684\n",
      "Epoch 7/10\n",
      "5068/5068 [==============================] - 19s 4ms/step - loss: 4.8268e-05 - acc: 1.0000 - val_loss: 0.0856 - val_acc: 0.9700\n",
      "Epoch 8/10\n",
      "5068/5068 [==============================] - 19s 4ms/step - loss: 8.1178e-06 - acc: 1.0000 - val_loss: 0.0993 - val_acc: 0.9684\n",
      "Epoch 9/10\n",
      "5068/5068 [==============================] - 19s 4ms/step - loss: 1.2274e-06 - acc: 1.0000 - val_loss: 0.1120 - val_acc: 0.9676\n",
      "Epoch 10/10\n",
      "2816/5068 [===============>..............] - ETA: 7s - loss: 3.5596e-07 - acc: 1.0000"
     ]
    }
   ],
   "source": [
    "# train the model\n",
    "\n",
    "history = model.fit(x_train, \n",
    "                    y_train,\n",
    "                    batch_size=128,\n",
    "                    epochs=10,\n",
    "                    validation_data=(x_val, y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot training & validation accuracy values\n",
    "\n",
    "plt.plot(history.history['acc'])\n",
    "plt.plot(history.history['val_acc'])\n",
    "plt.title('Model accuracy')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Test'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluate model\n",
    "\n",
    "def predict(X):\n",
    "    return np.rint(model.predict(X)) # threshold the predictions to retrieve labels\n",
    "\n",
    "train_acc, test_acc = evaluate_model(predict,\n",
    "                                     x_train, \n",
    "                                     y_train, \n",
    "                                     x_val, \n",
    "                                     y_val)\n",
    "print(\"Training Accuracy: {:.2f}%\".format(train_acc*100))\n",
    "print(\"Testing Accuracy: {:.2f}%\".format(test_acc*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# estimate 95% confidence interval\n",
    "\n",
    "n = x_val.shape[0]\n",
    "lb, ub = error_conf(1-test_acc, n)\n",
    "\n",
    "print(\"95% confidence interval: {:.2f}%-{:.2f}%\".format((1-ub)*100,(1-lb)*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
