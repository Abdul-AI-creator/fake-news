{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/lutzhamel/fake-news/blob/master/fake_news_classification.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "M_V4Ud4_jxTO"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "BI-hQADqjxTP"
      },
      "outputs": [],
      "source": [
        "MAX_SEQUENCE_LENGTH = 5000\n",
        "MAX_NUM_WORDS = 25000\n",
        "EMBEDDING_DIM = 300\n",
        "TEST_SPLIT = 0.2\n",
        "\n",
        "TEXT_DATA = 'https://raw.githubusercontent.com/lutzhamel/fake-news/master/data/fake_or_real_news.csv'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "ybJ-TLPCjxTQ"
      },
      "outputs": [],
      "source": [
        "# define a function that allows us to evaluate our models\n",
        "\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "def evaluate_model(predict_fun, X_train, y_train, X_test, y_test):\n",
        "    '''\n",
        "    evaluate the model, both training and testing errors are reported\n",
        "    '''\n",
        "    # training error\n",
        "    y_predict_train = predict_fun(X_train)\n",
        "    train_acc = accuracy_score(y_train,y_predict_train)\n",
        "    \n",
        "    # testing error\n",
        "    y_predict_test = predict_fun(X_test)\n",
        "    test_acc = accuracy_score(y_test,y_predict_test)\n",
        "    \n",
        "    return train_acc, test_acc"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "TZ24waD-jxTQ"
      },
      "outputs": [],
      "source": [
        "# estimate 95% confidence interval on error\n",
        "\n",
        "# NOTE: based on conversation on stackexchange: \n",
        "# https://stats.stackexchange.com/questions/247551/how-to-determine-the-confidence-of-a-neural-network-prediction\n",
        "# towards bottom of the page.\n",
        "\n",
        "from math import sqrt\n",
        "\n",
        "def error_conf(error, n):\n",
        "    term = 1.96*sqrt((error*(1-error))/n)\n",
        "    lb = error - term\n",
        "    ub = error + term\n",
        "    \n",
        "    return lb, ub"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "9fjCaUesjxTQ"
      },
      "outputs": [],
      "source": [
        "# read in our data and preprocess it\n",
        "\n",
        "df = pd.read_csv(TEXT_DATA)\n",
        "df.drop(labels=['id','title'], axis='columns', inplace=True)\n",
        "# only select stories with lengths gt 0 -- there are some texts with len = 0\n",
        "mask = list(df['text'].apply(lambda x: len(x) > 0))\n",
        "df = df[mask]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "TOZR1rhZjxTR",
        "outputId": "55d82319-764a-4a8e-8acf-b68723149aaf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 6335 texts.\n"
          ]
        }
      ],
      "source": [
        "# prepare text samples and their labels\n",
        "\n",
        "texts = df['text']\n",
        "labels = df['label']\n",
        "\n",
        "print('Found %s texts.' %texts.shape[0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "mJZQaPZMjxTR",
        "outputId": "6e72a309-1ff5-4d11-e6e4-083c7cb7850f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        }
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "# plot the distribution of article lengths in terms of word counts\n",
        "\n",
        "text_lengths = texts.apply(lambda x: len(x.split(\" \")))\n",
        "plt.hist(text_lengths)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BOfmXgMijxTS"
      },
      "source": [
        "## Naive Bayes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "SmsvkF4ljxTT"
      },
      "outputs": [],
      "source": [
        "# set up vector models for training and testing\n",
        "\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "\n",
        "# data vectorizer\n",
        "vectorizer = CountVectorizer(analyzer = \"word\", \n",
        "                             binary = True, \n",
        "                             min_df = 2,\n",
        "                             stop_words='english')\n",
        "docarray = vectorizer.fit_transform(texts).toarray()\n",
        "docterm = pd.DataFrame(docarray, columns=vectorizer.get_feature_names_out())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "uBej8h2sjxTT"
      },
      "outputs": [],
      "source": [
        "# create training and test data\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "docterm_train, docterm_test, y_train, y_test = train_test_split(docterm, labels, test_size=TEST_SPLIT)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "507u0btnjxTU",
        "outputId": "68b62bd4-d7c7-44a7-be62-e7d33d435fd9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "MultinomialNB()"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ],
      "source": [
        "# Naive Bayes Model\n",
        "\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "model = MultinomialNB()\n",
        "model.fit(docterm_train, y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "go5ws2VujxTU",
        "outputId": "85f5440d-e569-408e-b71b-675f00d6f1c7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Accuracy: 94.36%\n",
            "Testing Accuracy: 89.42%\n"
          ]
        }
      ],
      "source": [
        "# evaluate model\n",
        "\n",
        "train_acc, test_acc = evaluate_model(model.predict, docterm_train, y_train, docterm_test, y_test)\n",
        "print(\"Training Accuracy: {:.2f}%\".format(train_acc*100))\n",
        "print(\"Testing Accuracy: {:.2f}%\".format(test_acc*100))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "iltp-Iy6jxTU",
        "outputId": "1711c1a1-5b6b-4ddf-89d8-9b43179b6f37",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "95% confidence interval: 87.73%-91.12%\n"
          ]
        }
      ],
      "source": [
        "# estimate 95% confidence interval\n",
        "\n",
        "n = docterm_test.shape[0]\n",
        "lb, ub = error_conf(1-test_acc, n)\n",
        "\n",
        "print(\"95% confidence interval: {:.2f}%-{:.2f}%\".format((1-ub)*100,(1-lb)*100))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r9sNO19QjxTU"
      },
      "source": [
        "## Convolutional DNN"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "Q2M0Q6fijxTV",
        "outputId": "6375d03a-332f-4057-fa1d-990ef059d83a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 98817 unique tokens.\n",
            "Shape of data tensor: (6335, 5000)\n",
            "Shape of label tensor: (6335,)\n"
          ]
        }
      ],
      "source": [
        "# vectorize the text samples into a 2D integer tensor \n",
        "\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "\n",
        "tokenizer = Tokenizer(num_words=MAX_NUM_WORDS)\n",
        "tokenizer.fit_on_texts(texts)\n",
        "sequences = tokenizer.texts_to_sequences(texts)\n",
        "\n",
        "word_index = tokenizer.word_index\n",
        "num_words = min(MAX_NUM_WORDS, len(word_index)) + 1\n",
        "data = pad_sequences(sequences, \n",
        "                     maxlen=MAX_SEQUENCE_LENGTH, \n",
        "                     padding='pre', \n",
        "                     truncating='pre')\n",
        "\n",
        "print('Found %s unique tokens.' % len(word_index))\n",
        "print('Shape of data tensor:', data.shape)\n",
        "print('Shape of label tensor:', labels.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "vh-UnAyXjxTV"
      },
      "outputs": [],
      "source": [
        "# split the data into a training set and a validation set   \n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "x_train, x_val, y_train, y_val = train_test_split(data, \n",
        "                                                  labels.apply(lambda x: 0 if x == 'FAKE' else 1), \n",
        "                                                  test_size=TEST_SPLIT)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "IJrCDwL4jxTV",
        "outputId": "13c727b4-9ade-4158-e460-5b9c8f47e54e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding (Embedding)       (None, 5000, 300)         7500300   \n",
            "                                                                 \n",
            " conv1d (Conv1D)             (None, 4996, 128)         192128    \n",
            "                                                                 \n",
            " global_max_pooling1d (Globa  (None, 128)              0         \n",
            " lMaxPooling1D)                                                  \n",
            "                                                                 \n",
            " dense (Dense)               (None, 128)               16512     \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 1)                 129       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 7,709,069\n",
            "Trainable params: 7,709,069\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "# build a 1D convnet with global maxpooling                                                                      \n",
        "\n",
        "from keras import layers\n",
        "from keras.models import Sequential\n",
        "\n",
        "model = Sequential(\n",
        "    [\n",
        "        # part 1: word and sequence processing\n",
        "        layers.Embedding(num_words,\n",
        "                         EMBEDDING_DIM, \n",
        "                         input_length=MAX_SEQUENCE_LENGTH,\n",
        "                         trainable=True),\n",
        "        layers.Conv1D(128, 5, activation='relu'),\n",
        "        layers.GlobalMaxPooling1D(),\n",
        "        \n",
        "        # part 2: classification\n",
        "        layers.Dense(128, activation='relu'),\n",
        "        layers.Dense(1, activation='sigmoid')\n",
        "    ])\n",
        "\n",
        "model.compile(loss='binary_crossentropy',\n",
        "              optimizer='rmsprop',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "nII7SEYHjxTV",
        "outputId": "f0c1529b-df63-44bf-ee55-86dc3bb3b73c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 398
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            " 6/40 [===>..........................] - ETA: 9:28 - loss: 0.6792 - accuracy: 0.5521"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-16-9e198bd5c76d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m                     \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m128\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m                     \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m                     validation_data=(x_val, y_val))\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 64\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     65\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1214\u001b[0m                 _r=1):\n\u001b[1;32m   1215\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1216\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1217\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1218\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/util/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 150\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    151\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    908\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    909\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 910\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    911\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    912\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    940\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    941\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 942\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    943\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    944\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   3129\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[1;32m   3130\u001b[0m     return graph_function._call_flat(\n\u001b[0;32m-> 3131\u001b[0;31m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[0m\u001b[1;32m   3132\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3133\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1958\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1959\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0;32m-> 1960\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[1;32m   1961\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1962\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    601\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    602\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 603\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    604\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    605\u001b[0m           outputs = execute.execute_with_cancellation(\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     57\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0;32m---> 59\u001b[0;31m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[1;32m     60\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     61\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "# train the model\n",
        "\n",
        "history = model.fit(x_train, \n",
        "                    y_train,\n",
        "                    batch_size=128,\n",
        "                    epochs=10,\n",
        "                    validation_data=(x_val, y_val))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# all possible parameters history stores\n",
        "history.history.keys()"
      ],
      "metadata": {
        "id": "P2VpEuaDKxTG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "a2ns5YRvjxTV"
      },
      "outputs": [],
      "source": [
        "# Plot training & validation accuracy values\n",
        "\n",
        "plt.plot(history.history['accuracy'])\n",
        "plt.plot(history.history['val_accuracy'])\n",
        "plt.title('Model accuracy')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend(['Train', 'Test'], loc='upper left')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CQoSKxX1jxTV"
      },
      "outputs": [],
      "source": [
        "# evaluate model\n",
        "\n",
        "#def predict(X):\n",
        "#    return np.rint(model.predict(X)) # threshold the predictions to retrieve labels\n",
        "\n",
        "train_acc, test_acc = evaluate_model(lambda x: np.rint(model.predict(X)),\n",
        "                                     x_train, \n",
        "                                     y_train, \n",
        "                                     x_val, \n",
        "                                     y_val)\n",
        "print(\"Training Accuracy: {:.2f}%\".format(train_acc*100))\n",
        "print(\"Testing Accuracy: {:.2f}%\".format(test_acc*100))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZSYr6JiojxTW"
      },
      "outputs": [],
      "source": [
        "# estimate 95% confidence interval\n",
        "\n",
        "n = x_val.shape[0]\n",
        "lb, ub = error_conf(1-test_acc, n)\n",
        "\n",
        "print(\"95% confidence interval: {:.2f}%-{:.2f}%\".format((1-ub)*100,(1-lb)*100))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DMDZL4VbjxTW"
      },
      "outputs": [],
      "source": [
        ""
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.5"
    },
    "colab": {
      "name": "Copy of fake-news-classification.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "accelerator": "TPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}